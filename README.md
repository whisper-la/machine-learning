# 机器学习
>
>本内容主要是由本人学习西瓜书的笔记和代码练习构成
## 1. 绪论
### 1.1 基本术语
数据集：样本的集合表示数据集  
维数：数据有几个维度的特征  
泛化能力：模型对新的样本的适用程度，称为泛化能力，一般地训练样本越多，则模型的泛化能力越强。  
#### 关于假设空间和版本空间的辨析
**学习过程看作一个在所有假设(hypothesis)组成的空间中进行
搜索的过程，搜索目标是找到与训练集"匹配"(fit)的假设。**  

![image](https://github.com/whisper-la/machine-learning/assets/131673492/d0bdb4b0-af25-4322-8ed3-ffc99d8d6d47)
**<center>假设空间的计算方法</center>**
这里的4指的是共有三种性状，但是会有一种可能性为不论取值为多少都合适，所以为4。同时由于可能存在一种永远都不能取值的结果，所以再额外加一。  
可能有多个假设与训练集一致，即存在着一个与训练集一致的"假设集合"，我们称之为"**版本空间**"  
**归纳偏好**：机器学习算法在学习过程中对某种类型假设的偏好，称为"归纳偏好" (inductive bias)。  
归纳偏好可看作学习算法自身在一个可能很庞大的假设空间中对假设进行选择的启发式或"价值观"，即归纳偏好意味着哪一种模型会更好，如何去判定更好。
**算法的归纳偏好是否与问题本身匹配，大多数时候直接决定了算法能否取得好的性能。**
## 2.模型评估与选择
### 2.1 经验误差与过拟合
**错误率(error rate)**：分类错误的样本数占样本总数的比例称为，即如果在m个样本中有α个样本分类错误，则错误率E=α/m;  
**精度(accuracy)**：1-α/m,1-错误率  
**误差(error)**：实际预测输出与样本的真实输出之间的差异  
**训练误差(training error)**：学习器在训练集上的误差，也称为“经验误差”(empirical error)  
**泛化误差(generalization error)**：新样本上的误差  
**过拟合(overfitting)**：当学习器把训练样本学得"太好"了的时候，很可能巳经把训练样本自身的一些特点当作了所有潜在样本都会具有的一般性质，这样就会导致泛化性能下降这种现象。  
**欠拟合(underfitting)**：对训练样本的一般性质尚未学好.  
### 2.2 评估方法  
包括留出法 (hold-out)、交叉验证法(cross validation)、自助法(bootstrapping)
数据量充足的时候可以采用留出法或者交叉验证法，当数据量比较少、样本难以划分的时候采用自助法。  

### 2.3 性能度量
最常用的性能度量是均方误差。  
分类任务中常用的性能度量如下  
#### 2.3.1 错误率和精度
#### 2.3.2 查准率(precision)、查全率(recall)与 F1  

最常用的性能度量是均方误差。  
分类任务中常用的性能度量如下  
#### 2.3.1 错误率和精度
#### 2.3.2 查准率(precision)、查全率(recall)与 F1  
![image](https://github.com/whisper-la/machine-learning/assets/131673492/df702610-75af-4016-b7e0-025bfa78a577)
查准率和查全率是一对矛盾的度量工具。
![image](https://github.com/whisper-la/machine-learning/assets/131673492/5a649f40-6f5c-43ca-9bb7-40d78616c48c)
#### 2.3.3 ROC与AUC
##### ROCvv
ROC曲线的纵轴是"真正例率" (True Positive Rate，简称 TPR)，横轴是"假正例率" (False Positive Rate，简称 FPR)  
$$
TPR=\frac{TP}{TP+FN}  
$$
$$
FPR=\frac{FP}{FP+TN}
$$
![image](https://github.com/whisper-la/machine-learning/assets/131673492/0625b48a-03a1-468e-9d68-a18e5697054b)
AUC是曲线所围的阴影部分面积。
#### 2.3.4 代价敏感错误率与代价曲线
